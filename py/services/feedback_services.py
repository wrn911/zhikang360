import os
import re
import json
from datetime import datetime, timedelta
from sqlalchemy import create_engine, text
from sqlalchemy.orm import sessionmaker
from huggingface_hub import snapshot_download
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain.chains import RetrievalQA


# ===== 1. åµŒå…¥æ¨¡å‹ =====
def get_embeddings():
    model_path = snapshot_download(repo_id="BAAI/bge-small-zh-v1.5", repo_type="model")
    return HuggingFaceEmbeddings(
        model_name=model_path,
        model_kwargs={"device": "cuda:0"},
        encode_kwargs={"normalize_embeddings": True}
    )


# ===== 2. æ•°æ®åº“ä¼šè¯ =====
def get_session(settings_path="../settings.json"):
    with open(settings_path, encoding='utf-8') as f:
        db = json.load(f)['localdb']
    url = f"mysql+pymysql://{db['user']}:{db['password']}@{db['host']}:{db['port']}/{db['database']}"
    engine = create_engine(url)
    Session = sessionmaker(bind=engine)
    return Session()


# ===== 3. è·å–ç”¨æˆ·åˆ—è¡¨ =====
def get_all_user_ids(session):
    result = session.execute(text("SELECT id FROM user"))
    return [row[0] for row in result]


# ===== 4. è·å–æŒ‡å®šç”¨æˆ·æ‰€æœ‰åé¦ˆå¹¶æ ¼å¼åŒ– =====
def get_user_feedback_docs(session, user_id):
    result = session.execute(text(f"""
        SELECT content_food, content_sport, content_sleep, publish_time 
        FROM feedback WHERE user_id = {user_id}
    """))

    docs = []
    for i, row in enumerate(result):
        food, sport, sleep = row[0] or "", row[1] or "", row[2] or ""
        publish_time = str(row[3]) if row[3] else "æœªçŸ¥æ—¶é—´"
        text_block = (
            f"åé¦ˆæ—¶é—´ï¼š{publish_time}\n"
            f"é¥®é£Ÿåé¦ˆï¼š{food}\n"
            f"è¿åŠ¨åé¦ˆï¼š{sport}\n"
            f"ç¡çœ åé¦ˆï¼š{sleep}"
        ).strip()
        docs.append({
            "name": f"user_{user_id}_fb_{i}",
            "content": text_block,
            "date": publish_time
        })
    return docs


# ===== 5. æ„å»ºå‘é‡åº“ =====
def build_user_vectorstore(user_id, docs, persist_dir_root="./vector_store"):
    if not docs:
        print(f"âš ï¸ ç”¨æˆ· {user_id} æ— åé¦ˆå†…å®¹ï¼Œè·³è¿‡æ„å»ºå‘é‡åº“")
        return None  # æˆ– return ç©º vectorstore
    persist_dir = os.path.join(persist_dir_root, f"feedback_{user_id}")
    texts = [d["content"] for d in docs]
    metadatas = [{"name": d["name"], "date": d["date"]} for d in docs]

    embedding = get_embeddings()
    vectorstore = Chroma.from_texts(
        texts=texts,
        embedding=embedding,
        metadatas=metadatas,
        persist_directory=persist_dir
    )
    vectorstore.persist()
    print(f"âœ… ç”¨æˆ· {user_id} å‘é‡åº“æ„å»ºå®Œæˆï¼Œå…± {len(docs)} æ¡åé¦ˆ")
    return vectorstore

# ===== 6. å‘ç°æœ‰å‘é‡åº“è¿½åŠ æ–°æ–‡æ¡£ =====
def update_user_vectorstore(user_id, new_docs, persist_dir_root="./vector_store"):
    if not new_docs:
        print(f"âš ï¸ ç”¨æˆ· {user_id} æ›´æ–°å†…å®¹ä¸ºç©ºï¼Œè·³è¿‡æ›´æ–°")
        return

    persist_dir = os.path.join(persist_dir_root, f"feedback_{user_id}")
    embedding = get_embeddings()

    if os.path.exists(persist_dir):
        vectorstore = Chroma(persist_directory=persist_dir, embedding_function=embedding)

        # è·å–ç°æœ‰æ–‡æ¡£å†…å®¹ï¼Œç”¨äºå»é‡
        existing_docs = vectorstore.get()["documents"]
        existing_texts_set = set(existing_docs)

        # ç­›é€‰å»é‡åçš„æ–°æ–‡æ¡£
        unique_docs = [d for d in new_docs if d["content"] not in existing_texts_set]

        if not unique_docs:
            print(f"â„¹ï¸ ç”¨æˆ· {user_id} çš„æ–°å†…å®¹å·²å…¨éƒ¨å­˜åœ¨ï¼Œè·³è¿‡è¿½åŠ ")
            return

        texts = [d["content"] for d in unique_docs]
        metadatas = [{"name": d["name"], "date": d["date"]} for d in unique_docs]
        vectorstore.add_texts(texts, metadatas)
        vectorstore.persist()
        print(f"ğŸ†• ç”¨æˆ· {user_id} å‘é‡åº“å·²æ›´æ–°ï¼ˆæ–°å¢ {len(unique_docs)} æ¡ï¼‰")

    else:
        print(f"âš ï¸ å‘é‡åº“ä¸å­˜åœ¨ï¼Œä¸ºç”¨æˆ· {user_id} æ–°å»ºå‘é‡åº“")
        build_user_vectorstore(user_id, new_docs, persist_dir_root)



# ===== 7. åŠ è½½ç”¨æˆ·å‘é‡åº“ =====
def load_user_vectorstore(user_id, persist_dir_root="./vector_store"):
    persist_dir = os.path.join(persist_dir_root, f"feedback_{user_id}")
    embedding = get_embeddings()
    return Chroma(persist_directory=persist_dir, embedding_function=embedding)


# ===== 8. æå–é—®é¢˜ä¸­çš„æ—¶é—´çº¿ç´¢ =====
def extract_time_filter(question: str):
    question = question.lower()
    now = datetime.now()
    if "æœ€è¿‘" in question or "æœ€æ–°" in question:
        return now - timedelta(days=7)
    match = re.search(r"(\d{4})[-å¹´](\d{1,2})", question)
    if match:
        return datetime(int(match.group(1)), int(match.group(2)), 1)
    match = re.search(r"(\d{1,2})æœˆ", question)
    if match:
        return datetime(now.year, int(match.group(1)), 1)
    return None


# ===== 9. æŸ¥è¯¢ç”¨æˆ·åé¦ˆï¼ˆå«æ—¶é—´è¿‡æ»¤ï¼‰ =====
def query_user_feedback(user_id: int, question: str):
    print(f"\nğŸ” æŸ¥è¯¢ç”¨æˆ·{user_id}åé¦ˆï¼š{question}")
    vectorstore = load_user_vectorstore(user_id)
    retriever = vectorstore.as_retriever(search_kwargs={"k": 10})
    docs = retriever.get_relevant_documents(question)

    # è¿‡æ»¤æ—¶é—´
    time_threshold = extract_time_filter(question)
    if time_threshold:
        print(f"ğŸ•’ ä»…ä¿ç•™æ—¶é—´ >= {time_threshold.date()} çš„åé¦ˆ")
        docs = [
            doc for doc in docs
            if "date" in doc.metadata and str(doc.metadata["date"]) >= str(time_threshold.date())
        ]

    # æ„å»º QA æ¨¡æ¿
    prompt = ChatPromptTemplate.from_template(
        "ä½ æ˜¯ä¸€ä½å¥åº·åé¦ˆåˆ†æå¸ˆã€‚ä»¥ä¸‹æ˜¯ç”¨æˆ·è¿‡å¾€çš„å¥åº·åé¦ˆè®°å½•ï¼š\n"
        "{context}\n\n"
        "è¯·åŸºäºä¸Šè¿°å†…å®¹ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼š{question}\n"
        "ä¸è¦ç¼–é€ åé¦ˆæ•°æ®åº“ä¸­ä¸å­˜åœ¨çš„ä¿¡æ¯ã€‚"
    )

    llm = ChatOpenAI(temperature=0)
    chain = RetrievalQA.from_chain_type(
        llm=llm,
        retriever=lambda _: docs,
        chain_type="stuff",
        chain_type_kwargs={"prompt": prompt}
    )

    response = chain.run(question=question)
    print("ğŸ’¬ å›ç­”ï¼š", response)
    return response


# ===== 10. ä¸»ç¨‹åºï¼ˆæ„å»ºæ‰€æœ‰ç”¨æˆ·ï¼‰ =====
if __name__ == "__main__":
    print("å¼€å§‹ä¸ºæ‰€æœ‰ç”¨æˆ·æ„å»ºåé¦ˆå‘é‡åº“...")
    session = get_session()
    user_ids = get_all_user_ids(session)

    for user_id in user_ids:
        docs = get_user_feedback_docs(session, user_id)
        build_user_vectorstore(user_id, docs)

    session.close()
    print("âœ… æ‰€æœ‰ç”¨æˆ·å¤„ç†å®Œæˆï¼")

    # æµ‹è¯•æŸ¥è¯¢
    query_user_feedback(user_id=2, question="è¯·æ€»ç»“è¯¥ç”¨æˆ·æœ€è¿‘çš„ç¡çœ åé¦ˆ")
    query_user_feedback(user_id=2, question="è¯¥ç”¨æˆ·åœ¨5æœˆæœ‰å“ªäº›è¿åŠ¨å»ºè®®ï¼Ÿ")
